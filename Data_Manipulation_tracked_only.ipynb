{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "_xqyi_wWZA2h",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy as np\n",
    "import pickle\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSLc8oXIZA2k",
    "tags": []
   },
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "UDsXeahyZA2l",
    "outputId": "d4658b5c-b0b5-4eec-e434-898145338ee9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_path = \"./train/train\"\n",
    "train_path = \"./val_in/val_in\"\n",
    "training_samples = []\n",
    "# The glob module finds all the pathnames matching a specified pattern\n",
    "train_pkl_lst = glob(os.path.join(train_path, '*'))\n",
    "for i in range(np.array(train_pkl_lst).shape[0]):\n",
    "    with open(train_pkl_lst[i], 'rb') as f:\n",
    "        training_samples.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200,)\n"
     ]
    }
   ],
   "source": [
    "training_samples = np.array(training_samples)\n",
    "print(training_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['city', 'lane', 'lane_norm', 'scene_idx', 'agent_id', 'car_mask', 'p_in', 'v_in', 'track_id'])\n"
     ]
    }
   ],
   "source": [
    "print(training_samples[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PIT' 'MIA']\n"
     ]
    }
   ],
   "source": [
    "cities_arr = []\n",
    "for i in range(training_samples.shape[0]):\n",
    "    cities_arr.append(training_samples[i]['city'])\n",
    "cities_df = pd.DataFrame(cities_arr)\n",
    "print(cities_df[0].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# city can be either 'PIT' or 'MIA'\n",
    "# replace with binary representation\n",
    "# PIT is 0, MIA is 1\n",
    "for i in range(training_samples.shape[0]):\n",
    "    if training_samples[i]['city'] == 'PIT':\n",
    "        training_samples[i]['city'] = 0\n",
    "    elif training_samples[i]['city'] == 'MIA':\n",
    "        training_samples[i]['city'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "cities_arr = []\n",
    "for i in range(training_samples.shape[0]):\n",
    "    cities_arr.append(training_samples[i]['city'])\n",
    "cities_df = pd.DataFrame(cities_arr)\n",
    "print(cities_df[0].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200,)\n"
     ]
    }
   ],
   "source": [
    "# scene index gives us no information so it can be dropped\n",
    "scene_idx_arr = []\n",
    "for i in range(training_samples.shape[0]):\n",
    "    scene_idx_arr.append(training_samples[i]['scene_idx'])\n",
    "scene_idx_df = pd.DataFrame(scene_idx_arr)\n",
    "print(scene_idx_df[0].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop scene_idx\n",
    "for i in range(training_samples.shape[0]):\n",
    "    del training_samples[i]['scene_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000-0000-0000-0000-000000013270\n"
     ]
    }
   ],
   "source": [
    "print(training_samples[100]['agent_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2979,)\n",
      "00000000-0000-0000-0000-000000010910\n"
     ]
    }
   ],
   "source": [
    "# get unique values of Agent ID\n",
    "agent_id_arr = []\n",
    "for i in range(training_samples.shape[0]):\n",
    "    agent_id_arr.append(training_samples[i]['agent_id'])\n",
    "agent_id_df = pd.DataFrame(agent_id_arr)\n",
    "print(agent_id_df[0].unique().shape)\n",
    "print(agent_id_df[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2979,)\n",
      "00010910\n"
     ]
    }
   ],
   "source": [
    "# can replace last with only the last 8 values\n",
    "agent_id_arr = []\n",
    "for i in range(training_samples.shape[0]):\n",
    "    training_samples[i]['agent_id'] = training_samples[i]['agent_id'][-8:]\n",
    "    agent_id_arr.append(training_samples[i]['agent_id'])\n",
    "agent_id_df = pd.DataFrame(agent_id_arr)\n",
    "print(agent_id_df[0].unique().shape)\n",
    "print(agent_id_df[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2302,)\n"
     ]
    }
   ],
   "source": [
    "# for some reason the first track ID is always all 0s, lets remove that\n",
    "track_id_arr = []\n",
    "for i in range(training_samples.shape[0]):\n",
    "    training_samples[i]['track_id'] = np.delete(training_samples[i]['track_id'], 0)\n",
    "    track_id_arr.append(training_samples[i]['track_id'])\n",
    "track_id_df = pd.DataFrame(track_id_arr)\n",
    "print(track_id_df[0].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16863,)\n",
      "00000000-0000-0000-0000-000000010910\n"
     ]
    }
   ],
   "source": [
    "# we only need the last 8 values of track ID since the rest are zeros\n",
    "track_id_arr = []\n",
    "for i in range(training_samples.shape[0]):\n",
    "    for j in range(training_samples[i]['track_id'].shape[0]):\n",
    "        track_id_arr.append(training_samples[i]['track_id'][j])\n",
    "track_id_df = pd.DataFrame(track_id_arr)\n",
    "print(track_id_df[0].unique().shape)\n",
    "print(track_id_df[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16863,)\n",
      "00010910\n"
     ]
    }
   ],
   "source": [
    "# lets actually remove them\n",
    "track_id_arr = []\n",
    "for i in range(training_samples.shape[0]):\n",
    "    for j in range(training_samples[i]['track_id'].shape[0]):\n",
    "        training_samples[i]['track_id'][j] = training_samples[i]['track_id'][j][-8:]\n",
    "        track_id_arr.append(training_samples[i]['track_id'][j])\n",
    "track_id_df = pd.DataFrame(track_id_arr)\n",
    "print(track_id_df[0].unique().shape)\n",
    "print(track_id_df[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['city', 'lane', 'lane_norm', 'agent_id', 'car_mask', 'p_in', 'v_in', 'track_id'])\n"
     ]
    }
   ],
   "source": [
    "print(training_samples[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 2)\n"
     ]
    }
   ],
   "source": [
    "print(training_samples[0]['lane'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 95)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "# get only tracked agent info and normalized vector\n",
    "train_point_arr_x = []\n",
    "train_point_arr_y = []\n",
    "for scene_idx, data in enumerate(training_samples):\n",
    "    idx_track = 0\n",
    "    for i, j in enumerate(training_samples[scene_idx]['track_id']):\n",
    "        if training_samples[scene_idx]['agent_id']==j:\n",
    "            idx_track=i\n",
    "            break\n",
    "\n",
    "    tracked_positions = np.array(training_samples[scene_idx]['p_in'][idx_track]-training_samples[scene_idx]['p_in'][idx_track][0])\n",
    "    tracked_velocities = np.array(training_samples[scene_idx]['v_in'][idx_track])\n",
    "    tracked_velocity_norms = np.linalg.norm(training_samples[scene_idx]['v_in'][idx_track], axis=1)\n",
    "    \n",
    "    train_point = np.append(np.append(tracked_positions.flatten(), tracked_velocities.flatten()), tracked_velocity_norms)\n",
    "    train_point_arr_x.append(train_point)\n",
    "    \n",
    "    # train_point_arr_y.append(np.array(training_samples[scene_idx]['p_out'][idx_track]).flatten())\n",
    "    \n",
    "train_point_arr_x = np.array(train_point_arr_x)\n",
    "train_point_arr_y = np.array(train_point_arr_y)\n",
    "print(train_point_arr_x.shape)\n",
    "print(train_point_arr_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(train_point_arr_x, open(\"train_point_arr_x.p\", \"wb\"))\n",
    "# pickle.dump(train_point_arr_y, open(\"train_point_arr_y.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(train_point_arr_x, open(\"val_point_arr_x.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.90710449  0.75946045  1.72692871  1.44744873\n",
      "  2.54711914  2.13500977  3.36853027  2.8258667   4.27111816  3.57946777\n",
      "  5.08874512  4.26391602  5.91101074  4.95184326  6.80944824  5.70318604\n",
      "  7.62976074  6.38909912  8.44958496  7.07421875  9.26794434  7.75793457\n",
      " 10.08642578  8.44445801 10.98864746  9.19610596 11.80871582  9.88146973\n",
      " 12.62683105 10.56567383 13.52819824 11.32122803 14.35021973 12.00579834\n",
      " 15.16748047 12.68920898  8.52231884  7.13423395  9.07077694  7.59421206\n",
      "  8.19851398  6.88010645  8.20141506  6.87594032  8.21442795  6.9084959\n",
      "  9.02537918  7.53567648  8.17660046  6.84430504  8.22331619  6.87958813\n",
      "  8.98385525  7.51321602  8.20329666  6.85914564  8.19821739  6.85116768\n",
      "  8.18357944  6.83722019  8.18468094  6.86532688  9.0217762   7.51629257\n",
      "  8.20175266  6.85392761  8.18101501  6.84207535  9.01346779  7.5554204\n",
      "  8.2196722   6.84594965  8.17323303  6.83389473 11.11427967 11.83009091\n",
      " 10.70287327 10.70241862 10.73331925 11.75771616 10.66308147 10.72155129\n",
      " 11.71145038 10.69307977 10.68406603 10.66389012 10.68277657 11.74253379\n",
      " 10.68854857 10.66503642 11.76124904 10.69719766 10.65381882]\n"
     ]
    }
   ],
   "source": [
    "print(train_point_arr_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.           0.          -1.01525879  -0.89697266  -2.1776123\n",
      "  -1.9152832   -3.19616699  -2.77685547  -4.28979492  -3.80169678\n",
      "  -5.37182617  -4.68011475  -6.40429688  -5.52868652  -7.43225098\n",
      "  -6.38427734  -8.53405762  -7.36395264  -9.66455078  -8.30609131\n",
      " -10.71777344  -9.22680664 -11.81213379 -10.1361084  -12.80065918\n",
      " -10.93200684 -13.921875   -11.87414551 -15.02600098 -12.76947021\n",
      " -16.05786133 -13.64532471 -17.11706543 -14.53503418 -18.25720215\n",
      " -15.4831543  -19.34973145 -16.33978271 -10.03384399  -8.87351036\n",
      " -10.15268517  -8.9695797  -11.62311935 -10.18312263 -10.18486691\n",
      "  -8.61578369 -10.93676281 -10.24828243 -10.82073402  -8.78427601\n",
      " -10.32417583  -8.48564148 -10.27919674  -8.55607796 -11.01836777\n",
      "  -9.79698658 -11.30561352  -9.42138863 -10.53173733  -9.20701981\n",
      " -10.94385624  -9.09283924  -9.88493347  -7.95918941 -11.21180439\n",
      "  -9.42130184 -11.04222202  -8.95307255 -10.31856155  -8.75902939\n",
      " -10.59195518  -8.89668083 -11.40059471  -9.48131561 -10.92600346\n",
      "  -8.56602669  13.39467101  13.54733834  15.45292497  13.34028645\n",
      "  14.98799765  13.93742407  13.36393348  13.37416747  14.74399452\n",
      "  14.7166389   13.98880641  14.22841224  12.69096552  14.64464018\n",
      "  14.21577206  13.53489226  13.83258633  14.82797712  13.88360057]\n"
     ]
    }
   ],
   "source": [
    "print(train_point_arr_x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
