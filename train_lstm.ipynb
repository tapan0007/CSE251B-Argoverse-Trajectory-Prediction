{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea9f615f-1564-401f-9a74-8ac98f9bbeab",
   "metadata": {
    "id": "ea9f615f-1564-401f-9a74-8ac98f9bbeab",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import pickle\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8845100d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f04ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../train/train\"\n",
    "# The glob module finds all the pathnames matching a specified pattern\n",
    "train_pkl_lst = glob(os.path.join(train_path, '*'))\n",
    "with open(train_pkl_lst[1], 'rb') as f:\n",
    "    training_sample = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44b0f51-0779-49dc-bcab-5c284039d6fd",
   "metadata": {
    "id": "f44b0f51-0779-49dc-bcab-5c284039d6fd"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68fac99f-9f5e-4fb5-ba6c-e22cc6f8f8be",
   "metadata": {
    "id": "68fac99f-9f5e-4fb5-ba6c-e22cc6f8f8be"
   },
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        h_t, c_t = self.init_hidden(batch_size)\n",
    "\n",
    "        #print(x.size())\n",
    "        #print(x.size(-1))\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, (h_t, c_t) = self.lstm(x, (h_t, c_t))\n",
    "        \n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, h_t\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        h_0 = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "        c_0 =  torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)       \n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return h_0, c_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43901b7a-983c-49ca-b02a-e22d812f3cab",
   "metadata": {
    "id": "43901b7a-983c-49ca-b02a-e22d812f3cab"
   },
   "outputs": [],
   "source": [
    "# Autogressive vs. direct mapping\n",
    "# Batch Norm? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c020112-bb96-45d0-abf4-332956e8e544",
   "metadata": {
    "id": "1c020112-bb96-45d0-abf4-332956e8e544"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc5190e9-67a3-4e83-af0c-2f79f9cab867",
   "metadata": {
    "id": "cc5190e9-67a3-4e83-af0c-2f79f9cab867"
   },
   "outputs": [],
   "source": [
    "class ArgoverseDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data_path,\n",
    "                 sample_indices):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.sample_indices = sample_indices\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sample_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Load one scene\n",
    "        pkl_path = self.pkl_list[self.sample_indices[idx]]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            scene = pickle.load(f)\n",
    "            \n",
    "        # the index of agent to be predicted \n",
    "        pred_id = np.where(scene[\"track_id\"] == scene['agent_id'])[0][0]\n",
    "        \n",
    "        # input: p_in & v_in; output: p_out\n",
    "        inp_scene = np.dstack([scene['p_in'], scene['v_in']])\n",
    "        out_scene = np.dstack([scene['p_out'], scene['v_out']])\n",
    "        \n",
    "        # Normalization \n",
    "        min_vecs = np.min(inp_scene, axis = (0,1))\n",
    "        max_vecs = np.max(inp_scene, axis = (0,1))\n",
    "        \n",
    "        # Normalize by vectors\n",
    "        inp = (inp_scene[pred_id] - min_vecs)/(max_vecs - min_vecs)\n",
    "        out = (out_scene[pred_id] - min_vecs)/(max_vecs - min_vecs)\n",
    "        \n",
    "        dat = np.concatenate((inp, out), axis=0)\n",
    "        \n",
    "        # partition data into windows/intervals\n",
    "        train_data = []\n",
    "        window_size = 20\n",
    "        interval = 7\n",
    "        for i in range(0, len(dat), interval):\n",
    "            if i + window_size < len(dat): \n",
    "                train_data.append(dat[i:i+window_size])\n",
    "            \n",
    "        input_seq = []\n",
    "        target_seq = []\n",
    "        # store pairs of position and velocity at consecutive timesteps\n",
    "        for i in range(len(train_data)):\n",
    "            input_seq.append(train_data[i][:-1])\n",
    "            target_seq.append(train_data[i][1:])\n",
    "        \n",
    "        input_seq = np.array(input_seq, dtype=np.float32)\n",
    "        target_seq = np.array(target_seq, dtype=np.float32)\n",
    "        \n",
    "        return torch.from_numpy(input_seq).float(), torch.from_numpy(target_seq).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9237e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 30, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sample['p_out'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "834a1777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 30, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sample['v_out'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16e5f5c2-86ff-4a6b-a585-117d0d08b8b2",
   "metadata": {
    "id": "16e5f5c2-86ff-4a6b-a585-117d0d08b8b2"
   },
   "outputs": [],
   "source": [
    "# Try different ways of normalization\n",
    "# Leverage other features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ae604-526c-4fff-a672-f09cd103f7c2",
   "metadata": {
    "id": "c13ae604-526c-4fff-a672-f09cd103f7c2"
   },
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "913d832f-4050-4c23-9d74-114595112f13",
   "metadata": {
    "id": "913d832f-4050-4c23-9d74-114595112f13"
   },
   "outputs": [],
   "source": [
    "# Grid/Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29e5c051-43a7-4bfd-9ab0-7105693661d3",
   "metadata": {
    "id": "29e5c051-43a7-4bfd-9ab0-7105693661d3"
   },
   "outputs": [],
   "source": [
    "# batch_size = 64\n",
    "interval = 7 # sampling interval for LSTM\n",
    "window_size = 20 # number of timesteps to take as input\n",
    "batch_size = 512\n",
    "#in_dim = 19*4 # MLP\n",
    "#out_dim = 4 #30*2 # MLP\n",
    "input_size = 4 # LSTM\n",
    "output_size = 30*4 # LSTM (has to match input_size)\n",
    "hidden_dim = 32 #128 #256 #128 #32 #128\n",
    "num_layers = 2 #1 #3\n",
    "learning_rate = 0.01\n",
    "decay_rate = 0.95\n",
    "num_epoch = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7aa146-1618-4fc2-aec1-2724a09c8bd0",
   "metadata": {
    "id": "fb7aa146-1618-4fc2-aec1-2724a09c8bd0"
   },
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d589c9c9-c46b-4b70-a515-90dd68669431",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d589c9c9-c46b-4b70-a515-90dd68669431",
    "outputId": "34773f5c-9441-4dd7-903b-970cb0e59e99"
   },
   "outputs": [],
   "source": [
    "train_path = \"../train/train\"\n",
    "\n",
    "# total number of scenes\n",
    "indices = np.arange(0, 205942)\n",
    "\n",
    "# train-valid split\n",
    "np.random.shuffle(indices)\n",
    "train_indices = indices[:180000]\n",
    "valid_indices = indices[180000:]\n",
    "\n",
    "# define datasets\n",
    "train_set = ArgoverseDataset(train_path, train_indices)\n",
    "valid_set = ArgoverseDataset(train_path, valid_indices)\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ab0071e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "629f8c9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6df2d6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c45bc-bdf3-4b5a-82b0-c0752c16cd2b",
   "metadata": {
    "id": "6d9c45bc-bdf3-4b5a-82b0-c0752c16cd2b"
   },
   "source": [
    "# Model, Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c3cc020-8055-4005-ba6b-585a2e7a5fee",
   "metadata": {
    "id": "8c3cc020-8055-4005-ba6b-585a2e7a5fee"
   },
   "outputs": [],
   "source": [
    "# # RNN, LSTM, 1dCNN, Transformer\n",
    "# model = MLPNet(in_dim = in_dim, \n",
    "#                out_dim = out_dim,\n",
    "#                hidden_dim = hidden_dim, \n",
    "#                num_layers = num_layers).to(device) # move model to gpu \n",
    "\n",
    "model = MyLSTM(input_size=input_size, output_size=output_size, hidden_dim=hidden_dim, n_layers=num_layers).to(device)\n",
    "\n",
    "# Adaptive Moment Estimation computes adaptive learning rates for each parameter. \n",
    "# Compute the decaying averages of past and past squared gradients. \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=decay_rate)  # stepwise learning rate decay\n",
    "loss_fun = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f785cbe1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MyLSTM:\n\tMissing key(s) in state_dict: \"lstm.weight_ih_l1\", \"lstm.weight_hh_l1\", \"lstm.bias_ih_l1\", \"lstm.bias_hh_l1\". \n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([128, 76]) from checkpoint, the shape in current model is torch.Size([128, 4]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([60, 32]) from checkpoint, the shape in current model is torch.Size([120, 32]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([60]) from checkpoint, the shape in current model is torch.Size([120]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_137/4171988574.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lstm_hdim_32_wsize_20_interval_7_nlayers_1_bs_512_lr_0.01_decay_0.95_epoch_147.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MyLSTM:\n\tMissing key(s) in state_dict: \"lstm.weight_ih_l1\", \"lstm.weight_hh_l1\", \"lstm.bias_ih_l1\", \"lstm.bias_hh_l1\". \n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([128, 76]) from checkpoint, the shape in current model is torch.Size([128, 4]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([60, 32]) from checkpoint, the shape in current model is torch.Size([120, 32]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([60]) from checkpoint, the shape in current model is torch.Size([120])."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('lstm_hdim_32_wsize_20_interval_7_nlayers_1_bs_512_lr_0.01_decay_0.95_epoch_147.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "176e40ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'baseline.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_137/3123321283.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'baseline.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'baseline.pt'"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('baseline.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "09549dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = \"./train/train/\"\n",
    "# train_pkl_list = glob(os.path.join(train_path, '*'))\n",
    "# train_pkl_list.sort()\n",
    "\n",
    "# train_preds = []\n",
    "# for idx in range(3):\n",
    "#     with open(train_pkl_list[idx], 'rb') as f:\n",
    "#         train_sample = pickle.load(f)\n",
    "#         pred_id = np.where(train_sample[\"track_id\"] == train_sample['agent_id'])[0][0]\n",
    "#         inp_scene = np.dstack([train_sample['p_in'], train_sample['v_in']])\n",
    "\n",
    "#         # Normalization \n",
    "#         min_vecs = np.min(inp_scene, axis = (0,1))\n",
    "#         max_vecs = np.max(inp_scene, axis = (0,1))\n",
    "        \n",
    "#         inp = (inp_scene[pred_id] - min_vecs)/(max_vecs - min_vecs)\n",
    "        \n",
    "#         inp = torch.from_numpy(inp).float().to(device).unsqueeze(0)\n",
    "\n",
    "#         preds = model(inp).cpu().data.numpy()\n",
    "        \n",
    "#         # De-Normalization ! \n",
    "#         preds = preds * (max_vecs[:2] - min_vecs[:2]) +  min_vecs[:2]\n",
    "#         train_preds.append(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3392ee-eb57-4d8d-b6ea-49e6f38e3770",
   "metadata": {
    "id": "1c3392ee-eb57-4d8d-b6ea-49e6f38e3770"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "795977ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 5, 19, 4])\n",
      "torch.Size([512, 5, 19, 4])\n",
      "torch.Size([2560, 19, 4])\n",
      "tensor([[1.0000, 1.0000, 0.0566, 0.0473],\n",
      "        [0.9998, 0.9996, 0.0643, 0.0610],\n",
      "        [0.9995, 0.9992, 0.0543, 0.0229],\n",
      "        [0.9993, 0.9988, 0.1135, 0.1166],\n",
      "        [0.9991, 0.9984, 0.0722, 0.0608],\n",
      "        [0.9989, 0.9981, 0.1136, 0.1087],\n",
      "        [0.9987, 0.9977, 0.0845, 0.0779],\n",
      "        [0.9984, 0.9973, 0.0762, 0.0627],\n",
      "        [0.9982, 0.9969, 0.0633, 0.0508],\n",
      "        [0.9980, 0.9965, 0.0501, 0.0407],\n",
      "        [0.9978, 0.9962, 0.1454, 0.1404],\n",
      "        [0.9975, 0.9957, 0.0430, 0.0333],\n",
      "        [0.9973, 0.9954, 0.1270, 0.1274],\n",
      "        [0.9971, 0.9950, 0.0749, 0.0670],\n",
      "        [0.9969, 0.9946, 0.0619, 0.0524],\n",
      "        [0.9966, 0.9942, 0.0747, 0.0485],\n",
      "        [0.9964, 0.9938, 0.0602, 0.0563],\n",
      "        [0.9962, 0.9935, 0.1179, 0.1185],\n",
      "        [0.9959, 0.9930, 0.0306, 0.0269]])\n"
     ]
    }
   ],
   "source": [
    "for inp, tgt in train_loader:\n",
    "    print(inp.shape)\n",
    "    print(tgt.shape)\n",
    "    print(inp.view(-1, window_size-1, 4).size()) \n",
    "    print(inp[0, 0, :, :])\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa3e350d-9fca-4356-84da-7412d86667c9",
   "metadata": {
    "id": "fa3e350d-9fca-4356-84da-7412d86667c9"
   },
   "outputs": [],
   "source": [
    "def train_epoch(train_loader, model, optimizer, loss_function):\n",
    "\n",
    "    train_mse = []\n",
    "    for inp, tgt in tqdm(train_loader):\n",
    "        \n",
    "        inp = inp.view(-1, window_size-1, 4)\n",
    "        tgt = tgt.view(-1, window_size-1, 4)\n",
    "        \n",
    "        #print(inp.size())\n",
    "        \n",
    "        inp = inp.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        \n",
    "        output, hidden = model(inp)\n",
    "        output = output.to(device)\n",
    "        #print(output.shape)\n",
    "        #print(hidden.shape)\n",
    "        #print(tgt.view(-1, 4).size())\n",
    "        \n",
    "        loss = loss_function(output, tgt.view(-1, 4))\n",
    "        train_mse.append(loss.item()) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_mse = round(np.sqrt(np.mean(train_mse)),5)\n",
    "    \n",
    "    return train_mse\n",
    "\n",
    "def eval_epoch(valid_loader, model, loss_function):\n",
    "    \n",
    "    valid_mse = []\n",
    "    #preds = []\n",
    "    #trues = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inp, tgt in valid_loader:\n",
    "            \n",
    "            inp = inp.view(-1, window_size-1, 4)\n",
    "            tgt = tgt.view(-1, window_size-1, 4)\n",
    "            \n",
    "            inp = inp.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            \n",
    "            loss = 0\n",
    "            output, hidden = model(inp)\n",
    "            output = output.to(device)\n",
    "                    \n",
    "            loss = loss_function(output, tgt.view(-1, 4))\n",
    "            \n",
    "            #preds.append(pred.cpu().data.numpy())\n",
    "            #trues.append(tgt.cpu().data.numpy())\n",
    "            \n",
    "            valid_mse.append(loss.item())\n",
    "            \n",
    "        #preds = np.concatenate(preds, axis = 0)  \n",
    "        #trues = np.concatenate(trues, axis = 0)  \n",
    "        valid_mse = round(np.sqrt(np.mean(valid_mse)), 5)\n",
    "    return valid_mse#, preds, trues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f529da48-7092-4096-b95d-a3782e0a7590",
   "metadata": {
    "id": "f529da48-7092-4096-b95d-a3782e0a7590"
   },
   "outputs": [],
   "source": [
    "# Learning Rate Decay\n",
    "# Dropout\n",
    "# L1/L2 Regulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ec8f4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205942"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pkl_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f5c15057-a83e-44b0-af97-cf28f3c98044",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "f5c15057-a83e-44b0-af97-cf28f3c98044",
    "outputId": "c23108e3-db6e-4d40-8242-42cf968e5c13",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]\u001b[A/opt/conda/lib/python3.9/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([48640, 4])) that is different to the input size (torch.Size([48640, 120])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  0%|          | 0/352 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (120) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2556/2353138401.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# if you use dropout or batchnorm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_rmse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_rmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2556/2405571576.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(train_loader, model, optimizer, loss_function)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#print(tgt.view(-1, 4).size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3087\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3089\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3090\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (120) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "train_rmse = []\n",
    "valid_rmse = []\n",
    "min_rmse = 10e8\n",
    "\n",
    "for i in tqdm(range(num_epoch)):\n",
    "    start = time.time()\n",
    "\n",
    "    model.train() # if you use dropout or batchnorm. \n",
    "    train_rmse.append(train_epoch(train_loader, model, optimizer, loss_fun))\n",
    "    print(train_rmse)\n",
    "    \n",
    "    model.eval()\n",
    "    val_rmse = eval_epoch(valid_loader, model, loss_fun)\n",
    "    valid_rmse.append(val_rmse)\n",
    "    print(val_rmse)\n",
    "\n",
    "    # save the best model\n",
    "    if valid_rmse[-1] < min_rmse:\n",
    "        min_rmse = valid_rmse[-1] \n",
    "        best_model = model\n",
    "        \n",
    "        # torch.save([best_model, i, get_lr(optimizer)], name + \".pth\")\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    # Early Stopping\n",
    "    if (len(train_rmse) > 100 and np.mean(valid_rmse[-5:]) >= np.mean(valid_rmse[-10:-5])):\n",
    "        torch.save(best_model.state_dict(), f'lstm_hdim_{hidden_dim}_wsize_{window_size}_interval_{interval}_nlayers_{num_layers}_bs_{batch_size}_lr_{learning_rate}_decay_{decay_rate}_epoch_{i+1}.pt')    \n",
    "        break       \n",
    "\n",
    "    # Learning Rate Decay        \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(\"Epoch {} | T: {:0.2f} | Train RMSE: {:0.5f} | Valid RMSE: {:0.5f}\".format(i + 1, (end-start) / 60, train_rmse[-1], valid_rmse[-1]))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_rmse, label=\"train_rmse\")\n",
    "    plt.plot(valid_rmse, label=\"valid_rmse\")\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('RSME loss')\n",
    "    plt.title(f'RMSE loss curve for LSTM, hdim: {hidden_dim}, wsize: {window_size}, nlayers: {num_layers}, bs: {batch_size}, lr: {learning_rate}, decay: {decay_rate}')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'lstm_loss_curve_v1_hdim_{hidden_dim}_wsize_{window_size}_interval_{interval}_nlayers_{num_layers}_bs_{batch_size}_lr_{learning_rate}_decay_{decay_rate}.png')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540da579-31a5-462c-826b-e8e1c1a2ddd9",
   "metadata": {
    "id": "540da579-31a5-462c-826b-e8e1c1a2ddd9"
   },
   "source": [
    "# Evaluation and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f90248e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MyLSTM:\n\tMissing key(s) in state_dict: \"lstm.weight_ih_l1\", \"lstm.weight_hh_l1\", \"lstm.bias_ih_l1\", \"lstm.bias_hh_l1\". \n\tsize mismatch for fc.weight: copying a param with shape torch.Size([4, 32]) from checkpoint, the shape in current model is torch.Size([120, 32]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([120]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_137/523215427.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lstm_hdim_32_wsize_20_interval_7_nlayers_1_bs_512_lr_0.01_decay_0.95.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MyLSTM:\n\tMissing key(s) in state_dict: \"lstm.weight_ih_l1\", \"lstm.weight_hh_l1\", \"lstm.bias_ih_l1\", \"lstm.bias_hh_l1\". \n\tsize mismatch for fc.weight: copying a param with shape torch.Size([4, 32]) from checkpoint, the shape in current model is torch.Size([120, 32]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([120])."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('lstm_hdim_32_wsize_20_interval_7_nlayers_1_bs_512_lr_0.01_decay_0.95.pt'))\n",
    "best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cef337bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLSTM(\n",
       "  (lstm): LSTM(4, 128, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66654867-c45e-4ad2-bdb4-ce1d546ea2d2",
   "metadata": {
    "id": "66654867-c45e-4ad2-bdb4-ce1d546ea2d2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_path = \"../val_in/val_in/\"\n",
    "test_pkl_list = glob(os.path.join(test_path, '*'))\n",
    "test_pkl_list.sort()\n",
    "\n",
    "test_preds = []\n",
    "for idx in range(len(test_pkl_list)):\n",
    "    with open(test_pkl_list[idx], 'rb') as f:\n",
    "        test_sample = pickle.load(f)\n",
    "        pred_id = np.where(test_sample[\"track_id\"] == test_sample['agent_id'])[0][0]\n",
    "        inp_scene = np.dstack([test_sample['p_in'], test_sample['v_in']])\n",
    "\n",
    "        # Normalization \n",
    "        min_vecs = np.min(inp_scene, axis = (0,1))\n",
    "        max_vecs = np.max(inp_scene, axis = (0,1))\n",
    "        #print(min_vecs.shape)\n",
    "        #print(max_vecs.shape)\n",
    "        \n",
    "        inp = (inp_scene[pred_id] - min_vecs)/(max_vecs - min_vecs)\n",
    "        \n",
    "        inp = torch.from_numpy(inp).float().to(device).unsqueeze(0)\n",
    "\n",
    "        #print(inp)\n",
    "        # post-processing for LSTM\n",
    "        predictions = [[]]\n",
    "        inp_data = inp[0][-1]\n",
    "        #print(inp_data.size())\n",
    "        for i in range(30):\n",
    "            preds = best_model(inp_data.reshape(1, 1, 4))\n",
    "            predictions[0].append(preds[0].cpu().data.numpy()[0, :2])\n",
    "            #print(preds)\n",
    "            inp_data = preds[0]\n",
    "            \n",
    "#         print(inp[0][-1])\n",
    "#         preds = best_model(inp)#.cpu().data.numpy()\n",
    "#         print(preds)\n",
    "#         print(inp.shape)\n",
    "#         print(preds[0].shape)\n",
    "\n",
    "        predictions = np.array(predictions)\n",
    "        #print(predictions.shape)\n",
    "\n",
    "        # De-Normalization ! \n",
    "        predictions = predictions * (max_vecs[:2] - min_vecs[:2]) +  min_vecs[:2]\n",
    "        test_preds.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db582d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30, 2)\n",
      "[[[1719.4099948   336.36949324]\n",
      "  [1725.20331361  336.28454933]\n",
      "  [1731.18027481  336.08865915]\n",
      "  [1737.28438104  335.81118443]\n",
      "  [1743.46870725  335.4714306 ]\n",
      "  [1749.69527642  335.08248608]\n",
      "  [1755.93245834  334.65360004]\n",
      "  [1762.15403327  334.19208017]\n",
      "  [1768.33648664  333.70396898]\n",
      "  [1774.45859294  333.19495993]\n",
      "  [1780.5009995   332.67050654]\n",
      "  [1786.44518599  332.13593142]\n",
      "  [1792.27408876  331.59644814]\n",
      "  [1797.97168464  331.05707393]\n",
      "  [1803.52215851  330.52256425]\n",
      "  [1808.91240051  329.99732555]\n",
      "  [1814.12950884  329.48530616]\n",
      "  [1819.16245456  328.98986545]\n",
      "  [1824.00187347  328.51368654]\n",
      "  [1828.6402742   328.05881997]\n",
      "  [1833.07141396  327.62664   ]\n",
      "  [1837.29113087  327.21788833]\n",
      "  [1841.29734401  326.83256494]\n",
      "  [1845.08838863  326.47021175]\n",
      "  [1848.6650971   326.12975987]\n",
      "  [1852.02955035  325.80992226]\n",
      "  [1855.18507788  325.50908469]\n",
      "  [1858.13667393  325.22574199]\n",
      "  [1860.8907894   324.95851988]\n",
      "  [1863.4559561   324.70658941]]]\n"
     ]
    }
   ],
   "source": [
    "print(test_preds[0].shape)\n",
    "print(test_preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f945f2f3-2b73-471f-91e5-87c63eb06a77",
   "metadata": {
    "id": "f945f2f3-2b73-471f-91e5-87c63eb06a77"
   },
   "source": [
    "# Generate Submission File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477deb2e",
   "metadata": {},
   "source": [
    "### Steps to create submission file \n",
    "Run the below cells. The last cell will generate a submission file \"test_submission.csv\" that you can submit to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af9c27f8-a65b-48ce-861b-262c3f0422e6",
   "metadata": {
    "id": "af9c27f8-a65b-48ce-861b-262c3f0422e6"
   },
   "outputs": [],
   "source": [
    "# Submission Files\n",
    "sample_sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6b504543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for later use\n",
    "predictions = np.concatenate(test_preds).reshape(len(test_preds), -1)#.astype(int)\n",
    "sub_df = pd.DataFrame(np.c_[sample_sub[\"ID\"], predictions], columns=[np.r_[[\"ID\"], [\"v\" + str(i) for i in range(1, 61)]]])\n",
    "sub_df[\"ID\"] = sub_df[\"ID\"].astype(int)\n",
    "sub_df.to_csv(f'test_submission_lstm_hdim_{hidden_dim}_wsize_{window_size}_interval_{interval}_nlayers_{num_layers}_bs_{batch_size}_lr_{learning_rate}_decay_{decay_rate}.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f01524a4-5473-4c1f-9991-46fd62162e20",
   "metadata": {
    "id": "f01524a4-5473-4c1f-9991-46fd62162e20"
   },
   "outputs": [],
   "source": [
    "# Convert to float\n",
    "predictions = np.concatenate(test_preds).reshape(len(test_preds), -1)\n",
    "sub_df = pd.DataFrame(np.c_[sample_sub[\"ID\"], predictions], columns=[np.r_[[\"ID\"], [\"v\" + str(i) for i in range(1, 61)]]])\n",
    "sub_df[\"ID\"] = sub_df[\"ID\"].astype(int)\n",
    "sub_df.to_csv('test_submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "282ca735",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v51</th>\n",
       "      <th>v52</th>\n",
       "      <th>v53</th>\n",
       "      <th>v54</th>\n",
       "      <th>v55</th>\n",
       "      <th>v56</th>\n",
       "      <th>v57</th>\n",
       "      <th>v58</th>\n",
       "      <th>v59</th>\n",
       "      <th>v60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>1719.409995</td>\n",
       "      <td>336.369493</td>\n",
       "      <td>1725.203314</td>\n",
       "      <td>336.284549</td>\n",
       "      <td>1731.180275</td>\n",
       "      <td>336.088659</td>\n",
       "      <td>1737.284381</td>\n",
       "      <td>335.811184</td>\n",
       "      <td>1743.468707</td>\n",
       "      <td>...</td>\n",
       "      <td>1852.029550</td>\n",
       "      <td>325.809922</td>\n",
       "      <td>1855.185078</td>\n",
       "      <td>325.509085</td>\n",
       "      <td>1858.136674</td>\n",
       "      <td>325.225742</td>\n",
       "      <td>1860.890789</td>\n",
       "      <td>324.958520</td>\n",
       "      <td>1863.455956</td>\n",
       "      <td>324.706589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10015</td>\n",
       "      <td>727.496177</td>\n",
       "      <td>1228.487343</td>\n",
       "      <td>729.501623</td>\n",
       "      <td>1227.020683</td>\n",
       "      <td>731.551209</td>\n",
       "      <td>1225.541131</td>\n",
       "      <td>733.649858</td>\n",
       "      <td>1224.036116</td>\n",
       "      <td>735.807510</td>\n",
       "      <td>...</td>\n",
       "      <td>787.935138</td>\n",
       "      <td>1192.248323</td>\n",
       "      <td>789.823385</td>\n",
       "      <td>1191.082460</td>\n",
       "      <td>791.612788</td>\n",
       "      <td>1189.971742</td>\n",
       "      <td>793.303437</td>\n",
       "      <td>1188.914976</td>\n",
       "      <td>794.896137</td>\n",
       "      <td>1187.909617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10019</td>\n",
       "      <td>575.937420</td>\n",
       "      <td>1245.525411</td>\n",
       "      <td>577.949851</td>\n",
       "      <td>1246.229434</td>\n",
       "      <td>579.888580</td>\n",
       "      <td>1246.909017</td>\n",
       "      <td>581.766447</td>\n",
       "      <td>1247.556617</td>\n",
       "      <td>583.588199</td>\n",
       "      <td>...</td>\n",
       "      <td>618.134380</td>\n",
       "      <td>1208.988457</td>\n",
       "      <td>619.759209</td>\n",
       "      <td>1205.888133</td>\n",
       "      <td>621.359993</td>\n",
       "      <td>1202.839988</td>\n",
       "      <td>622.930811</td>\n",
       "      <td>1199.866418</td>\n",
       "      <td>624.466382</td>\n",
       "      <td>1196.988248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10028</td>\n",
       "      <td>1688.421868</td>\n",
       "      <td>315.642609</td>\n",
       "      <td>1686.011086</td>\n",
       "      <td>315.433464</td>\n",
       "      <td>1683.885100</td>\n",
       "      <td>315.277506</td>\n",
       "      <td>1682.060234</td>\n",
       "      <td>315.193592</td>\n",
       "      <td>1680.518450</td>\n",
       "      <td>...</td>\n",
       "      <td>1658.053798</td>\n",
       "      <td>317.807724</td>\n",
       "      <td>1656.362865</td>\n",
       "      <td>318.090679</td>\n",
       "      <td>1654.566922</td>\n",
       "      <td>318.396584</td>\n",
       "      <td>1652.656799</td>\n",
       "      <td>318.726605</td>\n",
       "      <td>1650.622822</td>\n",
       "      <td>319.082017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003</td>\n",
       "      <td>2124.988001</td>\n",
       "      <td>677.337634</td>\n",
       "      <td>2126.253720</td>\n",
       "      <td>676.509473</td>\n",
       "      <td>2127.818240</td>\n",
       "      <td>675.686718</td>\n",
       "      <td>2129.642917</td>\n",
       "      <td>674.856144</td>\n",
       "      <td>2131.708043</td>\n",
       "      <td>...</td>\n",
       "      <td>2218.717961</td>\n",
       "      <td>644.154731</td>\n",
       "      <td>2224.051100</td>\n",
       "      <td>642.274036</td>\n",
       "      <td>2229.361461</td>\n",
       "      <td>640.417128</td>\n",
       "      <td>2234.624730</td>\n",
       "      <td>638.597277</td>\n",
       "      <td>2239.818130</td>\n",
       "      <td>636.827166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>9897</td>\n",
       "      <td>256.107934</td>\n",
       "      <td>806.429025</td>\n",
       "      <td>256.087218</td>\n",
       "      <td>807.626338</td>\n",
       "      <td>256.094916</td>\n",
       "      <td>809.096276</td>\n",
       "      <td>256.088205</td>\n",
       "      <td>810.722548</td>\n",
       "      <td>256.036828</td>\n",
       "      <td>...</td>\n",
       "      <td>240.068192</td>\n",
       "      <td>856.978647</td>\n",
       "      <td>238.445174</td>\n",
       "      <td>858.486782</td>\n",
       "      <td>236.737045</td>\n",
       "      <td>859.748825</td>\n",
       "      <td>234.947427</td>\n",
       "      <td>860.738632</td>\n",
       "      <td>233.081285</td>\n",
       "      <td>861.434141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>99</td>\n",
       "      <td>588.224553</td>\n",
       "      <td>1155.657332</td>\n",
       "      <td>588.625253</td>\n",
       "      <td>1156.738643</td>\n",
       "      <td>589.040805</td>\n",
       "      <td>1157.748837</td>\n",
       "      <td>589.466163</td>\n",
       "      <td>1158.689328</td>\n",
       "      <td>589.894316</td>\n",
       "      <td>...</td>\n",
       "      <td>595.922750</td>\n",
       "      <td>1171.919051</td>\n",
       "      <td>596.053556</td>\n",
       "      <td>1172.410363</td>\n",
       "      <td>596.170164</td>\n",
       "      <td>1172.903513</td>\n",
       "      <td>596.272536</td>\n",
       "      <td>1173.400056</td>\n",
       "      <td>596.360345</td>\n",
       "      <td>1173.901477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>9905</td>\n",
       "      <td>1759.557891</td>\n",
       "      <td>444.402348</td>\n",
       "      <td>1763.731861</td>\n",
       "      <td>444.406015</td>\n",
       "      <td>1767.959124</td>\n",
       "      <td>444.195250</td>\n",
       "      <td>1772.224438</td>\n",
       "      <td>443.849696</td>\n",
       "      <td>1776.542309</td>\n",
       "      <td>...</td>\n",
       "      <td>1866.443332</td>\n",
       "      <td>422.076754</td>\n",
       "      <td>1869.704598</td>\n",
       "      <td>421.300012</td>\n",
       "      <td>1872.801255</td>\n",
       "      <td>420.583009</td>\n",
       "      <td>1875.730781</td>\n",
       "      <td>419.922832</td>\n",
       "      <td>1878.491704</td>\n",
       "      <td>419.315732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>9910</td>\n",
       "      <td>576.237940</td>\n",
       "      <td>1291.916656</td>\n",
       "      <td>577.363511</td>\n",
       "      <td>1294.875644</td>\n",
       "      <td>578.157823</td>\n",
       "      <td>1297.933344</td>\n",
       "      <td>578.671536</td>\n",
       "      <td>1301.083615</td>\n",
       "      <td>578.939946</td>\n",
       "      <td>...</td>\n",
       "      <td>541.070220</td>\n",
       "      <td>1382.560169</td>\n",
       "      <td>537.053684</td>\n",
       "      <td>1384.583994</td>\n",
       "      <td>532.847029</td>\n",
       "      <td>1386.130476</td>\n",
       "      <td>528.465023</td>\n",
       "      <td>1387.168444</td>\n",
       "      <td>523.925801</td>\n",
       "      <td>1387.676014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>9918</td>\n",
       "      <td>587.638949</td>\n",
       "      <td>1166.481728</td>\n",
       "      <td>589.380660</td>\n",
       "      <td>1168.105146</td>\n",
       "      <td>590.439682</td>\n",
       "      <td>1170.143350</td>\n",
       "      <td>591.029620</td>\n",
       "      <td>1172.422023</td>\n",
       "      <td>591.255681</td>\n",
       "      <td>...</td>\n",
       "      <td>543.506071</td>\n",
       "      <td>1214.570876</td>\n",
       "      <td>539.476751</td>\n",
       "      <td>1213.935318</td>\n",
       "      <td>535.429241</td>\n",
       "      <td>1212.952541</td>\n",
       "      <td>531.396316</td>\n",
       "      <td>1211.632288</td>\n",
       "      <td>527.412675</td>\n",
       "      <td>1209.989101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows  61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID           v1           v2           v3           v4           v5  \\\n",
       "0     10002  1719.409995   336.369493  1725.203314   336.284549  1731.180275   \n",
       "1     10015   727.496177  1228.487343   729.501623  1227.020683   731.551209   \n",
       "2     10019   575.937420  1245.525411   577.949851  1246.229434   579.888580   \n",
       "3     10028  1688.421868   315.642609  1686.011086   315.433464  1683.885100   \n",
       "4      1003  2124.988001   677.337634  2126.253720   676.509473  2127.818240   \n",
       "...     ...          ...          ...          ...          ...          ...   \n",
       "3195   9897   256.107934   806.429025   256.087218   807.626338   256.094916   \n",
       "3196     99   588.224553  1155.657332   588.625253  1156.738643   589.040805   \n",
       "3197   9905  1759.557891   444.402348  1763.731861   444.406015  1767.959124   \n",
       "3198   9910   576.237940  1291.916656   577.363511  1294.875644   578.157823   \n",
       "3199   9918   587.638949  1166.481728   589.380660  1168.105146   590.439682   \n",
       "\n",
       "               v6           v7           v8           v9  ...          v51  \\\n",
       "0      336.088659  1737.284381   335.811184  1743.468707  ...  1852.029550   \n",
       "1     1225.541131   733.649858  1224.036116   735.807510  ...   787.935138   \n",
       "2     1246.909017   581.766447  1247.556617   583.588199  ...   618.134380   \n",
       "3      315.277506  1682.060234   315.193592  1680.518450  ...  1658.053798   \n",
       "4      675.686718  2129.642917   674.856144  2131.708043  ...  2218.717961   \n",
       "...           ...          ...          ...          ...  ...          ...   \n",
       "3195   809.096276   256.088205   810.722548   256.036828  ...   240.068192   \n",
       "3196  1157.748837   589.466163  1158.689328   589.894316  ...   595.922750   \n",
       "3197   444.195250  1772.224438   443.849696  1776.542309  ...  1866.443332   \n",
       "3198  1297.933344   578.671536  1301.083615   578.939946  ...   541.070220   \n",
       "3199  1170.143350   591.029620  1172.422023   591.255681  ...   543.506071   \n",
       "\n",
       "              v52          v53          v54          v55          v56  \\\n",
       "0      325.809922  1855.185078   325.509085  1858.136674   325.225742   \n",
       "1     1192.248323   789.823385  1191.082460   791.612788  1189.971742   \n",
       "2     1208.988457   619.759209  1205.888133   621.359993  1202.839988   \n",
       "3      317.807724  1656.362865   318.090679  1654.566922   318.396584   \n",
       "4      644.154731  2224.051100   642.274036  2229.361461   640.417128   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "3195   856.978647   238.445174   858.486782   236.737045   859.748825   \n",
       "3196  1171.919051   596.053556  1172.410363   596.170164  1172.903513   \n",
       "3197   422.076754  1869.704598   421.300012  1872.801255   420.583009   \n",
       "3198  1382.560169   537.053684  1384.583994   532.847029  1386.130476   \n",
       "3199  1214.570876   539.476751  1213.935318   535.429241  1212.952541   \n",
       "\n",
       "              v57          v58          v59          v60  \n",
       "0     1860.890789   324.958520  1863.455956   324.706589  \n",
       "1      793.303437  1188.914976   794.896137  1187.909617  \n",
       "2      622.930811  1199.866418   624.466382  1196.988248  \n",
       "3     1652.656799   318.726605  1650.622822   319.082017  \n",
       "4     2234.624730   638.597277  2239.818130   636.827166  \n",
       "...           ...          ...          ...          ...  \n",
       "3195   234.947427   860.738632   233.081285   861.434141  \n",
       "3196   596.272536  1173.400056   596.360345  1173.901477  \n",
       "3197  1875.730781   419.922832  1878.491704   419.315732  \n",
       "3198   528.465023  1387.168444   523.925801  1387.676014  \n",
       "3199   531.396316  1211.632288   527.412675  1209.989101  \n",
       "\n",
       "[3200 rows x 61 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db08b55e-05e6-409e-b831-5f23ccd42ab3",
   "metadata": {
    "id": "db08b55e-05e6-409e-b831-5f23ccd42ab3"
   },
   "outputs": [],
   "source": [
    "# Ensemble Method "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
