{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ea9f615f-1564-401f-9a74-8ac98f9bbeab",
   "metadata": {
    "executionInfo": {
     "elapsed": 9663,
     "status": "ok",
     "timestamp": 1682205872583,
     "user": {
      "displayName": "Dev Gulati",
      "userId": "17053533454866203676"
     },
     "user_tz": 420
    },
    "id": "ea9f615f-1564-401f-9a74-8ac98f9bbeab",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import pickle\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "OmXuKzlHSJhe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1682205878064,
     "user": {
      "displayName": "Dev Gulati",
      "userId": "17053533454866203676"
     },
     "user_tz": 420
    },
    "id": "OmXuKzlHSJhe",
    "outputId": "1111f7c9-8a79-4bf3-a31e-49aa92794685",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c020112-bb96-45d0-abf4-332956e8e544",
   "metadata": {
    "id": "1c020112-bb96-45d0-abf4-332956e8e544"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cc5190e9-67a3-4e83-af0c-2f79f9cab867",
   "metadata": {
    "id": "cc5190e9-67a3-4e83-af0c-2f79f9cab867",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArgoverseDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data_path,\n",
    "                 sample_indices):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.sample_indices = sample_indices\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sample_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load one scene\n",
    "        pkl_path = self.pkl_list[self.sample_indices[idx]]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            scene = pickle.load(f)\n",
    "            \n",
    "        # the index of agent to be predicted \n",
    "        pred_id = np.where(scene[\"track_id\"] == scene['agent_id'])[0][0]\n",
    "        \n",
    "        inp = {}\n",
    "        # input: p_in & v_in; output: p_out\n",
    "        inp['p_in'] = scene['p_in'][pred_id]\n",
    "        inp['v_in'] = scene['v_in'][pred_id]\n",
    "        acc_in = []\n",
    "        for i, v in enumerate(inp['v_in']):\n",
    "            if i==0:\n",
    "                continue\n",
    "            acc_in.append((inp['v_in'][i]-inp['v_in'][i-1])/(2/19))\n",
    "        inp['acc_in'] = np.array(acc_in)\n",
    "        # inp = np.append(np.append(p_in, v_in), acc_in)\n",
    "        # print(inp.shape)\n",
    "        \n",
    "        p_out = scene['p_out'][pred_id]\n",
    "        # v_out = scene['v_out'][pred_id]/np.linalg.norm(scene['v_out'][pred_id], axis=0).flatten()\n",
    "        # acc_out = []\n",
    "        # for i, v in enumerate(v_out):\n",
    "        #     if i==len(v_out) or i==0:\n",
    "        #         continue\n",
    "        #     acc_out.append((v_out[i]-v_out[i-1])/(3/30))\n",
    "        # acc_out = np.array(acc_out).flatten()\n",
    "        # out = np.append(np.append(p_out, v_out), acc_out)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        # Convert to float torch tensor\n",
    "        return inp, p_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "913d832f-4050-4c23-9d74-114595112f13",
   "metadata": {
    "id": "913d832f-4050-4c23-9d74-114595112f13",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grid/Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "29e5c051-43a7-4bfd-9ab0-7105693661d3",
   "metadata": {
    "id": "29e5c051-43a7-4bfd-9ab0-7105693661d3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "in_dim = 112\n",
    "out_dim = 30*2\n",
    "hidden_dim = 128\n",
    "num_layers = 3\n",
    "learning_rate = 0.01\n",
    "decay_rate = 0.95\n",
    "num_epoch = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7aa146-1618-4fc2-aec1-2724a09c8bd0",
   "metadata": {
    "id": "fb7aa146-1618-4fc2-aec1-2724a09c8bd0",
    "tags": []
   },
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d589c9c9-c46b-4b70-a515-90dd68669431",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1682203235553,
     "user": {
      "displayName": "Dev Gulati",
      "userId": "17053533454866203676"
     },
     "user_tz": 420
    },
    "id": "d589c9c9-c46b-4b70-a515-90dd68669431",
    "outputId": "34773f5c-9441-4dd7-903b-970cb0e59e99",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = \"./train/train\"\n",
    "\n",
    "# total number of scenes\n",
    "indices = np.arange(0, 205942)\n",
    "\n",
    "# train-valid split\n",
    "np.random.shuffle(indices)\n",
    "train_indices = indices[:180000]\n",
    "valid_indices = indices[180000:]\n",
    "\n",
    "# define datasets\n",
    "train_set = ArgoverseDataset(train_path, train_indices)\n",
    "valid_set = ArgoverseDataset(train_path, valid_indices)\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=True, num_workers=0)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b4565fcc-27cd-448c-86c2-61aefb8f3b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def model(inp, tgt):\n",
    "#     time = 2/19\n",
    "#     pred = []\n",
    "#     next_acc_arr = []\n",
    "#     next_vel_arr = []\n",
    "#     next_position_arr = []\n",
    "    \n",
    "#     acc_delta = (inp['acc_in'][:,-2]-inp['acc_in'][:,-1])/(time)\n",
    "#     next_acc = inp['acc_in'][:,-1]+(acc_delta)*(time)\n",
    "#     next_acc_arr.append(inp['acc_in'][:,-1])\n",
    "#     next_acc_arr.append(next_acc)\n",
    "    \n",
    "#     next_vel = inp['v_in'][:, -1]+inp['acc_in'][:,-1]*(time)\n",
    "#     next_vel_arr.append(next_vel)\n",
    "    \n",
    "#     next_position = inp['p_in'][:,-1]+inp['v_in'][:,-1]*(time)\n",
    "#     next_position_arr.append(next_position)\n",
    "    \n",
    "#     pred.append(next_position)\n",
    "\n",
    "#     for i in range(29):\n",
    "#         time = 3/30\n",
    "#         acc_delta = (next_acc_arr[:][-2]-next_acc_arr[:][-1])/(time)        \n",
    "#         next_acc = next_acc_arr[:][-1]+(acc_delta[:][-1])*(time)\n",
    "#         next_vel = next_vel_arr[:][-1]+next_acc_arr[:][-1]*(time)\n",
    "#         next_position = next_position_arr[:][-1]+next_vel_arr[:][-1]*(time)\n",
    "        \n",
    "#         next_vel_arr.append(next_vel)\n",
    "#         next_acc_arr.append(next_acc)\n",
    "#         next_position_arr.append(next_position)\n",
    "#         pred.append(next_position)\n",
    "#     print('---------')\n",
    "#     print(pred[0])\n",
    "#     print(tgt[0])\n",
    "#     return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "35643ea1-1755-40c4-9e7d-6ad1246c9b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model(inp):\n",
    "    time = 2/19\n",
    "    positions = inp['p_in']\n",
    "    \n",
    "    curr_position = positions[:,-1]\n",
    "    prev_position = positions[:,-2]\n",
    "\n",
    "    prev_prev_position = positions[:,-3]\n",
    "    prev_prev_prev_position = positions[:,-4]\n",
    "    \n",
    "    curr_velocity = (curr_position-prev_position)/time\n",
    "    prev_velocity = (prev_position-prev_prev_position)/time\n",
    "    prev_prev_velocity = (prev_prev_position-prev_prev_prev_position)/time\n",
    "    \n",
    "    curr_acceleration = (curr_velocity-prev_velocity)/time\n",
    "    prev_acceleration = (prev_velocity-prev_prev_velocity)/time\n",
    "    \n",
    "    curr_acc_change = (curr_acceleration-prev_acceleration)/time\n",
    "    \n",
    "    pred_acceleration = curr_acceleration+curr_acc_change*time\n",
    "    pred_velocity = curr_velocity+curr_acceleration*time\n",
    "    pred_position = curr_position+curr_velocity*time\n",
    "    \n",
    "    positions = np.append(positions[0], pred_position, axis=0)\n",
    "    \n",
    "    for i in range(29):\n",
    "        # need to alter times to correspond to right ones\n",
    "        if i==0:\n",
    "            time = 3/30\n",
    "            time_prev = time_prev_prev = 2/19\n",
    "        elif i==1:\n",
    "            time = time_prev = 3/30\n",
    "            time_prev_prev = 2/19\n",
    "        else:\n",
    "            time = time_prev = time_prev_prev = 3/30\n",
    "        curr_position = positions[:][-1]\n",
    "        prev_position = positions[:][-2]\n",
    "        prev_prev_position = positions[:][-3]\n",
    "        prev_prev_prev_position = positions[:][-4]\n",
    "        \n",
    "        curr_velocity = (curr_position-prev_position)/time\n",
    "        prev_velocity = (prev_position-prev_prev_position)/time_prev\n",
    "        prev_prev_velocity = (prev_prev_position-prev_prev_prev_position)/time_prev_prev\n",
    "\n",
    "        curr_acceleration = (curr_velocity-prev_velocity)/time\n",
    "        prev_acceleration = (prev_velocity-prev_prev_velocity)/time_prev\n",
    "\n",
    "        curr_acc_change = (curr_acceleration-prev_acceleration)/time\n",
    "\n",
    "        pred_acceleration = curr_acceleration+curr_acc_change*time\n",
    "        pred_velocity = curr_velocity+curr_acceleration*time\n",
    "        pred_position = curr_position+curr_velocity*time\n",
    "        positions = np.reshape(np.append(positions, pred_position), (-1, 2))\n",
    "        \n",
    "\n",
    "    # print('---------')\n",
    "    # print(positions[0])\n",
    "    # print(tgt[0])\n",
    "    return positions[19:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e70cb203-cdda-4f61-9f15-5449732e5a54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.47798\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "train_mse = []\n",
    "\n",
    "for inp, tgt in train_loader:\n",
    "    tgt = np.reshape(tgt, (30, 2))\n",
    "    # pred = torch.cat(model(inp, tgt))\n",
    "    pred=model(inp)\n",
    "    loss = MSE(pred, tgt)\n",
    "    train_mse.append(loss) \n",
    "train_mse = round(np.sqrt(np.mean(train_mse)), 5)\n",
    "print(train_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9c681f4f-19f4-41df-a380-57b9d2ee143a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.47515\n"
     ]
    }
   ],
   "source": [
    "valid_mse = []\n",
    "preds = []\n",
    "trues = []\n",
    "for inp, tgt in valid_loader:\n",
    "    loss = 0\n",
    "    pred = model(inp)\n",
    "    tgt = np.reshape(tgt, (30, 2))\n",
    "    loss = MSE(pred, tgt)\n",
    "    preds.append(pred)\n",
    "    trues.append(tgt)\n",
    "    valid_mse.append(loss.item())\n",
    "\n",
    "preds = np.concatenate(preds, axis = 0)  \n",
    "trues = np.concatenate(trues, axis = 0)  \n",
    "valid_mse = round(np.sqrt(np.mean(valid_mse)), 5)\n",
    "print(valid_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540da579-31a5-462c-826b-e8e1c1a2ddd9",
   "metadata": {
    "id": "540da579-31a5-462c-826b-e8e1c1a2ddd9"
   },
   "source": [
    "# Evaluation and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "66654867-c45e-4ad2-bdb4-ce1d546ea2d2",
   "metadata": {
    "id": "66654867-c45e-4ad2-bdb4-ce1d546ea2d2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:21: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "test_path = \"./val_in/val_in/\"\n",
    "test_pkl_list = glob(os.path.join(test_path, '*'))\n",
    "test_pkl_list.sort()\n",
    "\n",
    "test_preds = []\n",
    "for idx in range(len(test_pkl_list)):\n",
    "    with open(test_pkl_list[idx], 'rb') as f:\n",
    "        scene = pickle.load(f)\n",
    "        # the index of agent to be predicted \n",
    "        pred_id = np.where(scene[\"track_id\"] == scene['agent_id'])[0][0]\n",
    "        \n",
    "        inp = {}\n",
    "        # input: p_in & v_in; output: p_out\n",
    "        inp['p_in'] = np.array([scene['p_in'][pred_id]])\n",
    "        inp['v_in'] = torch.tensor(scene['v_in'][pred_id])\n",
    "        acc_in = []\n",
    "        for i, v in enumerate(inp['v_in']):\n",
    "            if i==0:\n",
    "                continue\n",
    "            acc_in.append((inp['v_in'][i]-inp['v_in'][i-1])/(2/19))\n",
    "        inp['acc_in'] = np.array(acc_in)\n",
    "        preds = model(inp)\n",
    "        \n",
    "        test_preds.append(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f945f2f3-2b73-471f-91e5-87c63eb06a77",
   "metadata": {
    "id": "f945f2f3-2b73-471f-91e5-87c63eb06a77"
   },
   "source": [
    "# Generate Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "af9c27f8-a65b-48ce-861b-262c3f0422e6",
   "metadata": {
    "id": "af9c27f8-a65b-48ce-861b-262c3f0422e6"
   },
   "outputs": [],
   "source": [
    "# # Submission Files\n",
    "sample_sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f01524a4-5473-4c1f-9991-46fd62162e20",
   "metadata": {
    "id": "f01524a4-5473-4c1f-9991-46fd62162e20"
   },
   "outputs": [],
   "source": [
    "# Convert to int\n",
    "predictions = np.concatenate(test_preds).reshape(len(test_preds), -1).astype(int)\n",
    "sub_df = pd.DataFrame(np.c_[sample_sub[\"ID\"], predictions], columns=[np.r_[[\"ID\"], [\"v\" + str(i) for i in range(1, 61)]]])\n",
    "sub_df.to_csv('test_submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGiqLaD1PEDW",
   "metadata": {
    "id": "RGiqLaD1PEDW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
