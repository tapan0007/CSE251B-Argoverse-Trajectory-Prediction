{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    " This notebook uses train as an example.\n",
    " Change to the val folder for evaluation \n",
    "\"\"\"\n",
    "\n",
    "new_path = \"./train/train\"\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51486\n"
     ]
    }
   ],
   "source": [
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1563/2953006989.py:7: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  inp = torch.LongTensor(inp)\n",
      "/tmp/ipykernel_1563/2953006989.py:8: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  out = torch.LongTensor(out)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1YAAAC0CAYAAACXOL1/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMoUlEQVR4nO3dTWgc9xkH4HekyO32A6ngXiy76GLSiwMJog29tQH7EArGhUCh0IPvhR5CGwjGmIIDufXUS6CHQCG0wdBTDCWnQAImhjiHGB8ioigUalotlKpElaYHZa3VaGc1q92dz+eBxexoF/6XNftj3ve3SZqmaQAAAHBqC1UfAAAAoOkEKwAAgCkJVgAAAFMSrAAAAKYkWAEAAEzpqUlefPbs2VhbW5vTUaD9NjY2fIZgCj5DMJ2NjY2ICJ8jmMLGxkY8fvz42PWJgtXa2lrcu3dvZoeCrllfX/cZgin4DMF01tfXIyJ8jmAKg89RllFAAACAKQlWAAAAUxKsAAAApjTRjhX1dOf+Vrz+zsP4Ynsnzq304uUrT8fVZ1erPhYAUALfA9rhy5vLsZQePt9NIs7c7Fd3ICbmjlXD3bm/Fa+8/SC2tncijYit7Z145e0Hcef+VtVHAwDmzPeAdhiEqiQ5fCylB9dpDsGq4V5/52Hs7O4dubazuxevv/OwohMBAGXxPaAdBqFq2CBc0RxGARvui+2dia4DAM02PPqX973b9wAonztWDXdupTfRdQCgubKjf3l8D4DyCVYN9/KVp6O3tHjkWm9pMV6+8nRFJwIA5mXU6F+W7wHNs5tEpJmknKYH12kOwarhrj67GrevXYrVlV4kEbG60ovb1y5pAwKAFho34ud7QHOdudl/Eq4GD62AzWPHqgWuPrvqP1AAaKnhnaqFJIm97K2NOAhU7/32JxWcjlnJhqgzFZ2D0xOsAABqarBTNRj/GxWqjP5BPQhWAAA1lbdTtZgksZ+mfhAYakSwAgCoieGxv3MrvdjK2anaT9P49LUXSz4dMI5gBQBQA9mxv63tnUgiRtaqq1OH+tEKCABQA6PG/tI4aPsbZqcK6kmwAgCogbwq9TTCz6pAAxgFBACoiCp1aA/BCgCgAqrUoV0EKwCACqhSh3YRrAAA5iRbn/7j73833v3kH/HF9s7Itr8IVerQVIIVAMAcjKpPf/P9z058nyp1aCatgAAAc5A36jeOnSpoLnesAADmIK8+fZQkwk4VNJxgBQAwI0Xq07PUqUM7CFYAADNQpD49y+gftIcdKwCAGRhXn57EwZ2pXzz/vVhd6T15fvvaJaN/0BLuWAEAnNLw6J/6dOg2wQoA4BSyo3951KdDNxgFBAA4hSJ16naooDvcsQIAOIVxderq06F7BCsAgIKK1KmrT4duEqwAAAooUqdu9A+6S7ACAChgXJ36fpoa/YOOE6wAAHKoUweKEqwAAEZQpw5MQt06AMAI6tSBSbhjBQAwgjp1YBKCFQBAHN2nOrfSi+XeUmzv7B57nTp1YBTBCgDovOw+1db2TiwtJrG0kMTu/mFthdE/II8dKwCg80btU+3upfGtrz8Vqyu9SOLgTtXta5eM/gEjuWMFAHRSkSr17f/sxv0bl0s9F9BMghUA0Dmq1IFZMwoIAHSOKnVg1tyxAgA6R5U6MGuCFQDQCa/eeRB/+mAz9tK8jSpV6sDpCVYAQOu9eudBvPn+Z2NfY/QPmIZgBQC03p8+2Mz9m9E/YBYEKwCg9caN/3362oslngRoK8EKAGil4d+pyrOYJCWeCGgzwQoAaJ2iv1P18x9eKOlEQNsJVgBA65z0O1WLSRI//+GF+N3VSyWeCmgzwQoAaJ288b8k7FQB87FQ9QEAAGbt3EpvousA0xKsAIDWefnK09FbWjxyze9UAfNkFBAAaJ3B71ENWgH9ThUwb4IVANAIw/Xp51Z68ePvfzfe/eQfucHp6rOrghRQGsEKAKi9bH361vZOvPn+Z0/+vrW9E6+8/SAiQpgCKmHHCgCovZPq0yMidnb34vV3HpZ0IoCj3LECAGppePQvLfievJp1gHkTrACA2smO/hWlTh2oilFAAKB2ioz+ZalTB6okWAEAtTNupC+JiNWVXvzi+e/F6krvyfPb1y4prgAqYxQQAKjeR29F/O1WRP/ziOXz8ctv/Sz++O8fHHvZ6kov3vvtTyo4IMB4ghUAUK2P3or4668idr+6S9XfjFcX/xD/PvO/+POXP3ryMqN+QJ0ZBQQAqvW3W4eh6itP7f03bn3zL0b9gMZwxwoAKN/w6F9Omfo3dv4e79009gc0g2AFAJQrO/qXZ/l8OecBmAGjgABAuUaM/h2z1It44UY55wGYAcEKAChX//Mxf0wili9E/PT3Ec+8VNqRAKZlFBAAKNfy+Yj+5ojrFyJ+/XH55wGYAXesAIByXbw82XWABhCsAIByPbo72XWABjAKCADMX4F69fG7VwD1JlgBAPOlXh3oAKOAAMB8qVcHOkCwAgDmS7060AFGAQEiYv/GciTJ4fM0jVi41a/uQNB0wztVyUJEunf8NerVgRZxxwrovEGoyj72byxXfTRopsFOVX8zItLRocroH9AyghXQeYMgddI1oKC8napkMYz+AW1lFBAAmF6ROvV0P+LmdpmnAiiNYAUATEedOoBRQIA0PXicdA3IoU4dQLACWLjVfxKkhh9aAaEgdeoARgEBIo6HKL0VkDG8Q7V8PuLi5YhHd9WpA3xFsAIAxsvuUPU3I+69cfh3deoARgEBgBMU2aGKUKcOdJo7VgDAUdmxv/5msfepUwc6TLACAA6NGvuLJHJ/m2qYOnWgw4wCAgCHRo79pXFipYudKqDjBCsA4FBudXp6sDs12KFav370uZ0qoOOMAgJA1w3vVKlOBzgVwQoAuiy7U6U6HeBUjAICQJflVamrTgeYiDtWANA1w6N/eW1/qtMBJiJYAUCXZEf/8qhOB5iIUUAA6JK80b9hdqoAJiZYAUCX5NapR9ipAjg9o4AA0Hbq1AHmTrACgDZTpw5QCqOAANBm6tQBSuGOFQC0jTp1gNIJVgDQJurUASphFBAA2kSdOkAlBCsAaBN16gCVMAoIAE2nTh2gcoIVADSZOnWAWjAKCABNpk4doBbcsQKAJsvbqVKnDlAqwQoA6m54h2r5fMTFyxGP7p6wU6VOHaBMghUA1Fl2h6q/GXHvjcO/26kCqAU7VgBQZ0V+lyrCThVAxdyxAoA6yY799TeLvc9OFUClBCsAqItRY3+RRER68nvtVAFUyiggANTFyLG/NA7C1Rh2qgAqJ1gBQF3kVadHerA7NdihWr9+9LmdKoDKGQUEgLrI26lavhDx64/LPw8AhbljBQB1cfHyZNcBqA3BCgDq4tHdya4DUBtGAQGgSsP16nntf7m7VwDUhWAFAFXJ1qvnUaUOUHtGAQGgKiPr1TNUqQM0gmAFAFUZO+KnSh2gSYwCAkCZhneqkoWIdO/4a9SrAzSOYAUAZcnuVI0KVUb/ABrJKCAAlCVvpypZDKN/AM3mjhUAzFOROvV0P+LmdpmnAmDGBCsAmBd16gCdYRQQAOZFnTpAZwhWADAv6tQBOsMoIADMkjp1gE4SrABgVtSpA3SWUUAAmBV16gCd5Y4VAExieNRv+XzExcsRj+6qUwfoOMEKAIrKjvr1NyPuvXHy+9SpA7SeUUAAKKpIfXqWnSqAThCsAKCosfXpWXaqALrEKCAA5MnuU/W+E7Hzz5Pfp04doHMEKwAYZdQ+1eKZiIWliP3d/PcZ/QPoJKOAADDKqH2qvS8jvvbtgztSg1G/9etHnxv9A+gkd6wAYGB49C+vOn3nXxG/+bTUYwFQf4IVAEQcH/3LozodgBGMAgJARLEqdftTAOQQrAAg4oQqdftTAIxnFBCA7hreqUoWItK9469RnQ5AAYIVAN2U3akaFaqM/gFQkFFAALopb6cqWQyjfwBMyh0rALqjSJ16uh9xc7vMUwHQAoIVAN2gTh2AOTIKCEA3qFMHYI4EKwC6QZ06AHNkFLAF9m8sR5IcPk/TiIVb/eoOBFCV4R2q5fMRFy9HPLqrTh2oPd/nms8dq4YbfAizj/0by1UfDaBcgx2q/mZEpAf/3nvj8Lk6daCmfJ9rB8Gq4QYfvJOuAbRekR2qCHXqQO34PtcORgEBaIexO1RD1KkDMAfuWAHQDkVr0tWpAzAHglXDpenB46RrAK33wo2Dnalx7FQBNeT7XDsIVg23cKv/5IM3/NAiA3TOMy8d7EwtX4gnO1Tr148+t1MF1JDvc+1gx6oFsh86e45AZz3zkuAENJLvc83njhUAAMCUBCsAAIApJWlafC3u7Nmzsba2NsfjQLt9+OGH8dxzz1V9DGgsnyGYzsbGRkSE73MwhY2NjXj8+PGx6xMFKwAAAI4zCggAADAlwQoAAGBKghUAAMCUBCsAAIApCVYAAABTEqwAAACmJFgBAABMSbACAACYkmAFAAAwpf8DRKFFAwenJ7oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x216 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "agent_id = 3\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(val_loader):\n",
    "    inp, out = sample_batch\n",
    "    \"\"\"TODO:\n",
    "      Deep learning model\n",
    "      training routine\n",
    "    \"\"\"\n",
    "    show_sample_batch(sample_batch, agent_id)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
